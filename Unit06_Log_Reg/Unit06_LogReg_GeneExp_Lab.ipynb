{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unit06_LogReg_GeneExp_Lab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEjO3gXSCODW"
      },
      "source": [
        "# **Lab: Logistic Regression for Gene Expression Data**\n",
        "\n",
        "Using logistic regression to predict biological characteristics, i.e. \"phenotypes\" from gene expression data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqukOEofC57O"
      },
      "source": [
        "Loading modules and data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfcdbdsrCGq-"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn import linear_model, preprocessing"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7L75jkTDCzv",
        "outputId": "4b584061-60bd-41dc-e33e-24889c041cbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "df = pd.read_excel(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls\", index_col=0)\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DYRK1A_N</th>\n",
              "      <th>ITSN1_N</th>\n",
              "      <th>BDNF_N</th>\n",
              "      <th>NR1_N</th>\n",
              "      <th>NR2A_N</th>\n",
              "      <th>pAKT_N</th>\n",
              "      <th>pBRAF_N</th>\n",
              "      <th>pCAMKII_N</th>\n",
              "      <th>pCREB_N</th>\n",
              "      <th>pELK_N</th>\n",
              "      <th>pERK_N</th>\n",
              "      <th>pJNK_N</th>\n",
              "      <th>PKCA_N</th>\n",
              "      <th>pMEK_N</th>\n",
              "      <th>pNR1_N</th>\n",
              "      <th>pNR2A_N</th>\n",
              "      <th>pNR2B_N</th>\n",
              "      <th>pPKCAB_N</th>\n",
              "      <th>pRSK_N</th>\n",
              "      <th>AKT_N</th>\n",
              "      <th>BRAF_N</th>\n",
              "      <th>CAMKII_N</th>\n",
              "      <th>CREB_N</th>\n",
              "      <th>ELK_N</th>\n",
              "      <th>ERK_N</th>\n",
              "      <th>GSK3B_N</th>\n",
              "      <th>JNK_N</th>\n",
              "      <th>MEK_N</th>\n",
              "      <th>TRKA_N</th>\n",
              "      <th>RSK_N</th>\n",
              "      <th>APP_N</th>\n",
              "      <th>Bcatenin_N</th>\n",
              "      <th>SOD1_N</th>\n",
              "      <th>MTOR_N</th>\n",
              "      <th>P38_N</th>\n",
              "      <th>pMTOR_N</th>\n",
              "      <th>DSCR1_N</th>\n",
              "      <th>AMPKA_N</th>\n",
              "      <th>NR2B_N</th>\n",
              "      <th>pNUMB_N</th>\n",
              "      <th>...</th>\n",
              "      <th>TIAM1_N</th>\n",
              "      <th>pP70S6_N</th>\n",
              "      <th>NUMB_N</th>\n",
              "      <th>P70S6_N</th>\n",
              "      <th>pGSK3B_N</th>\n",
              "      <th>pPKCG_N</th>\n",
              "      <th>CDK5_N</th>\n",
              "      <th>S6_N</th>\n",
              "      <th>ADARB1_N</th>\n",
              "      <th>AcetylH3K9_N</th>\n",
              "      <th>RRP1_N</th>\n",
              "      <th>BAX_N</th>\n",
              "      <th>ARC_N</th>\n",
              "      <th>ERBB4_N</th>\n",
              "      <th>nNOS_N</th>\n",
              "      <th>Tau_N</th>\n",
              "      <th>GFAP_N</th>\n",
              "      <th>GluR3_N</th>\n",
              "      <th>GluR4_N</th>\n",
              "      <th>IL1B_N</th>\n",
              "      <th>P3525_N</th>\n",
              "      <th>pCASP9_N</th>\n",
              "      <th>PSD95_N</th>\n",
              "      <th>SNCA_N</th>\n",
              "      <th>Ubiquitin_N</th>\n",
              "      <th>pGSK3B_Tyr216_N</th>\n",
              "      <th>SHH_N</th>\n",
              "      <th>BAD_N</th>\n",
              "      <th>BCL2_N</th>\n",
              "      <th>pS6_N</th>\n",
              "      <th>pCFOS_N</th>\n",
              "      <th>SYP_N</th>\n",
              "      <th>H3AcK18_N</th>\n",
              "      <th>EGR1_N</th>\n",
              "      <th>H3MeK4_N</th>\n",
              "      <th>CaNA_N</th>\n",
              "      <th>Genotype</th>\n",
              "      <th>Treatment</th>\n",
              "      <th>Behavior</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MouseID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>309_1</th>\n",
              "      <td>0.503644</td>\n",
              "      <td>0.747193</td>\n",
              "      <td>0.430175</td>\n",
              "      <td>2.816329</td>\n",
              "      <td>5.990152</td>\n",
              "      <td>0.218830</td>\n",
              "      <td>0.177565</td>\n",
              "      <td>2.373744</td>\n",
              "      <td>0.232224</td>\n",
              "      <td>1.750936</td>\n",
              "      <td>0.687906</td>\n",
              "      <td>0.306382</td>\n",
              "      <td>0.402698</td>\n",
              "      <td>0.296927</td>\n",
              "      <td>1.022060</td>\n",
              "      <td>0.605673</td>\n",
              "      <td>1.877684</td>\n",
              "      <td>2.308745</td>\n",
              "      <td>0.441599</td>\n",
              "      <td>0.859366</td>\n",
              "      <td>0.416289</td>\n",
              "      <td>0.369608</td>\n",
              "      <td>0.178944</td>\n",
              "      <td>1.866358</td>\n",
              "      <td>3.685247</td>\n",
              "      <td>1.537227</td>\n",
              "      <td>0.264526</td>\n",
              "      <td>0.319677</td>\n",
              "      <td>0.813866</td>\n",
              "      <td>0.165846</td>\n",
              "      <td>0.453910</td>\n",
              "      <td>3.037621</td>\n",
              "      <td>0.369510</td>\n",
              "      <td>0.458539</td>\n",
              "      <td>0.335336</td>\n",
              "      <td>0.825192</td>\n",
              "      <td>0.576916</td>\n",
              "      <td>0.448099</td>\n",
              "      <td>0.586271</td>\n",
              "      <td>0.394721</td>\n",
              "      <td>...</td>\n",
              "      <td>0.482864</td>\n",
              "      <td>0.294170</td>\n",
              "      <td>0.182150</td>\n",
              "      <td>0.842725</td>\n",
              "      <td>0.192608</td>\n",
              "      <td>1.443091</td>\n",
              "      <td>0.294700</td>\n",
              "      <td>0.354605</td>\n",
              "      <td>1.339070</td>\n",
              "      <td>0.170119</td>\n",
              "      <td>0.159102</td>\n",
              "      <td>0.188852</td>\n",
              "      <td>0.106305</td>\n",
              "      <td>0.144989</td>\n",
              "      <td>0.176668</td>\n",
              "      <td>0.125190</td>\n",
              "      <td>0.115291</td>\n",
              "      <td>0.228043</td>\n",
              "      <td>0.142756</td>\n",
              "      <td>0.430957</td>\n",
              "      <td>0.247538</td>\n",
              "      <td>1.603310</td>\n",
              "      <td>2.014875</td>\n",
              "      <td>0.108234</td>\n",
              "      <td>1.044979</td>\n",
              "      <td>0.831557</td>\n",
              "      <td>0.188852</td>\n",
              "      <td>0.122652</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.106305</td>\n",
              "      <td>0.108336</td>\n",
              "      <td>0.427099</td>\n",
              "      <td>0.114783</td>\n",
              "      <td>0.131790</td>\n",
              "      <td>0.128186</td>\n",
              "      <td>1.675652</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_2</th>\n",
              "      <td>0.514617</td>\n",
              "      <td>0.689064</td>\n",
              "      <td>0.411770</td>\n",
              "      <td>2.789514</td>\n",
              "      <td>5.685038</td>\n",
              "      <td>0.211636</td>\n",
              "      <td>0.172817</td>\n",
              "      <td>2.292150</td>\n",
              "      <td>0.226972</td>\n",
              "      <td>1.596377</td>\n",
              "      <td>0.695006</td>\n",
              "      <td>0.299051</td>\n",
              "      <td>0.385987</td>\n",
              "      <td>0.281319</td>\n",
              "      <td>0.956676</td>\n",
              "      <td>0.587559</td>\n",
              "      <td>1.725774</td>\n",
              "      <td>2.043037</td>\n",
              "      <td>0.445222</td>\n",
              "      <td>0.834659</td>\n",
              "      <td>0.400364</td>\n",
              "      <td>0.356178</td>\n",
              "      <td>0.173680</td>\n",
              "      <td>1.761047</td>\n",
              "      <td>3.485287</td>\n",
              "      <td>1.509249</td>\n",
              "      <td>0.255727</td>\n",
              "      <td>0.304419</td>\n",
              "      <td>0.780504</td>\n",
              "      <td>0.157194</td>\n",
              "      <td>0.430940</td>\n",
              "      <td>2.921882</td>\n",
              "      <td>0.342279</td>\n",
              "      <td>0.423560</td>\n",
              "      <td>0.324835</td>\n",
              "      <td>0.761718</td>\n",
              "      <td>0.545097</td>\n",
              "      <td>0.420876</td>\n",
              "      <td>0.545097</td>\n",
              "      <td>0.368255</td>\n",
              "      <td>...</td>\n",
              "      <td>0.454519</td>\n",
              "      <td>0.276431</td>\n",
              "      <td>0.182086</td>\n",
              "      <td>0.847615</td>\n",
              "      <td>0.194815</td>\n",
              "      <td>1.439460</td>\n",
              "      <td>0.294060</td>\n",
              "      <td>0.354548</td>\n",
              "      <td>1.306323</td>\n",
              "      <td>0.171427</td>\n",
              "      <td>0.158129</td>\n",
              "      <td>0.184570</td>\n",
              "      <td>0.106592</td>\n",
              "      <td>0.150471</td>\n",
              "      <td>0.178309</td>\n",
              "      <td>0.134275</td>\n",
              "      <td>0.118235</td>\n",
              "      <td>0.238073</td>\n",
              "      <td>0.142037</td>\n",
              "      <td>0.457156</td>\n",
              "      <td>0.257632</td>\n",
              "      <td>1.671738</td>\n",
              "      <td>2.004605</td>\n",
              "      <td>0.109749</td>\n",
              "      <td>1.009883</td>\n",
              "      <td>0.849270</td>\n",
              "      <td>0.200404</td>\n",
              "      <td>0.116682</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.106592</td>\n",
              "      <td>0.104315</td>\n",
              "      <td>0.441581</td>\n",
              "      <td>0.111974</td>\n",
              "      <td>0.135103</td>\n",
              "      <td>0.131119</td>\n",
              "      <td>1.743610</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_3</th>\n",
              "      <td>0.509183</td>\n",
              "      <td>0.730247</td>\n",
              "      <td>0.418309</td>\n",
              "      <td>2.687201</td>\n",
              "      <td>5.622059</td>\n",
              "      <td>0.209011</td>\n",
              "      <td>0.175722</td>\n",
              "      <td>2.283337</td>\n",
              "      <td>0.230247</td>\n",
              "      <td>1.561316</td>\n",
              "      <td>0.677348</td>\n",
              "      <td>0.291276</td>\n",
              "      <td>0.381002</td>\n",
              "      <td>0.281710</td>\n",
              "      <td>1.003635</td>\n",
              "      <td>0.602449</td>\n",
              "      <td>1.731873</td>\n",
              "      <td>2.017984</td>\n",
              "      <td>0.467668</td>\n",
              "      <td>0.814329</td>\n",
              "      <td>0.399847</td>\n",
              "      <td>0.368089</td>\n",
              "      <td>0.173905</td>\n",
              "      <td>1.765544</td>\n",
              "      <td>3.571456</td>\n",
              "      <td>1.501244</td>\n",
              "      <td>0.259614</td>\n",
              "      <td>0.311747</td>\n",
              "      <td>0.785154</td>\n",
              "      <td>0.160895</td>\n",
              "      <td>0.423187</td>\n",
              "      <td>2.944136</td>\n",
              "      <td>0.343696</td>\n",
              "      <td>0.425005</td>\n",
              "      <td>0.324852</td>\n",
              "      <td>0.757031</td>\n",
              "      <td>0.543620</td>\n",
              "      <td>0.404630</td>\n",
              "      <td>0.552994</td>\n",
              "      <td>0.363880</td>\n",
              "      <td>...</td>\n",
              "      <td>0.447197</td>\n",
              "      <td>0.256648</td>\n",
              "      <td>0.184388</td>\n",
              "      <td>0.856166</td>\n",
              "      <td>0.200737</td>\n",
              "      <td>1.524364</td>\n",
              "      <td>0.301881</td>\n",
              "      <td>0.386087</td>\n",
              "      <td>1.279600</td>\n",
              "      <td>0.185456</td>\n",
              "      <td>0.148696</td>\n",
              "      <td>0.190532</td>\n",
              "      <td>0.108303</td>\n",
              "      <td>0.145330</td>\n",
              "      <td>0.176213</td>\n",
              "      <td>0.132560</td>\n",
              "      <td>0.117760</td>\n",
              "      <td>0.244817</td>\n",
              "      <td>0.142445</td>\n",
              "      <td>0.510472</td>\n",
              "      <td>0.255343</td>\n",
              "      <td>1.663550</td>\n",
              "      <td>2.016831</td>\n",
              "      <td>0.108196</td>\n",
              "      <td>0.996848</td>\n",
              "      <td>0.846709</td>\n",
              "      <td>0.193685</td>\n",
              "      <td>0.118508</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.108303</td>\n",
              "      <td>0.106219</td>\n",
              "      <td>0.435777</td>\n",
              "      <td>0.111883</td>\n",
              "      <td>0.133362</td>\n",
              "      <td>0.127431</td>\n",
              "      <td>1.926427</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_4</th>\n",
              "      <td>0.442107</td>\n",
              "      <td>0.617076</td>\n",
              "      <td>0.358626</td>\n",
              "      <td>2.466947</td>\n",
              "      <td>4.979503</td>\n",
              "      <td>0.222886</td>\n",
              "      <td>0.176463</td>\n",
              "      <td>2.152301</td>\n",
              "      <td>0.207004</td>\n",
              "      <td>1.595086</td>\n",
              "      <td>0.583277</td>\n",
              "      <td>0.296729</td>\n",
              "      <td>0.377087</td>\n",
              "      <td>0.313832</td>\n",
              "      <td>0.875390</td>\n",
              "      <td>0.520293</td>\n",
              "      <td>1.566852</td>\n",
              "      <td>2.132754</td>\n",
              "      <td>0.477671</td>\n",
              "      <td>0.727705</td>\n",
              "      <td>0.385639</td>\n",
              "      <td>0.362970</td>\n",
              "      <td>0.179449</td>\n",
              "      <td>1.286277</td>\n",
              "      <td>2.970137</td>\n",
              "      <td>1.419710</td>\n",
              "      <td>0.259536</td>\n",
              "      <td>0.279218</td>\n",
              "      <td>0.734492</td>\n",
              "      <td>0.162210</td>\n",
              "      <td>0.410615</td>\n",
              "      <td>2.500204</td>\n",
              "      <td>0.344509</td>\n",
              "      <td>0.429211</td>\n",
              "      <td>0.330121</td>\n",
              "      <td>0.746980</td>\n",
              "      <td>0.546763</td>\n",
              "      <td>0.386860</td>\n",
              "      <td>0.547849</td>\n",
              "      <td>0.366771</td>\n",
              "      <td>...</td>\n",
              "      <td>0.442650</td>\n",
              "      <td>0.398534</td>\n",
              "      <td>0.161768</td>\n",
              "      <td>0.760234</td>\n",
              "      <td>0.184169</td>\n",
              "      <td>1.612382</td>\n",
              "      <td>0.296382</td>\n",
              "      <td>0.290680</td>\n",
              "      <td>1.198765</td>\n",
              "      <td>0.159799</td>\n",
              "      <td>0.166112</td>\n",
              "      <td>0.185323</td>\n",
              "      <td>0.103184</td>\n",
              "      <td>0.140656</td>\n",
              "      <td>0.163804</td>\n",
              "      <td>0.123210</td>\n",
              "      <td>0.117439</td>\n",
              "      <td>0.234947</td>\n",
              "      <td>0.145068</td>\n",
              "      <td>0.430996</td>\n",
              "      <td>0.251103</td>\n",
              "      <td>1.484624</td>\n",
              "      <td>1.957233</td>\n",
              "      <td>0.119883</td>\n",
              "      <td>0.990225</td>\n",
              "      <td>0.833277</td>\n",
              "      <td>0.192112</td>\n",
              "      <td>0.132781</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.103184</td>\n",
              "      <td>0.111262</td>\n",
              "      <td>0.391691</td>\n",
              "      <td>0.130405</td>\n",
              "      <td>0.147444</td>\n",
              "      <td>0.146901</td>\n",
              "      <td>1.700563</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_5</th>\n",
              "      <td>0.434940</td>\n",
              "      <td>0.617430</td>\n",
              "      <td>0.358802</td>\n",
              "      <td>2.365785</td>\n",
              "      <td>4.718679</td>\n",
              "      <td>0.213106</td>\n",
              "      <td>0.173627</td>\n",
              "      <td>2.134014</td>\n",
              "      <td>0.192158</td>\n",
              "      <td>1.504230</td>\n",
              "      <td>0.550960</td>\n",
              "      <td>0.286961</td>\n",
              "      <td>0.363502</td>\n",
              "      <td>0.277964</td>\n",
              "      <td>0.864912</td>\n",
              "      <td>0.507990</td>\n",
              "      <td>1.480059</td>\n",
              "      <td>2.013697</td>\n",
              "      <td>0.483416</td>\n",
              "      <td>0.687794</td>\n",
              "      <td>0.367531</td>\n",
              "      <td>0.355311</td>\n",
              "      <td>0.174836</td>\n",
              "      <td>1.324695</td>\n",
              "      <td>2.896334</td>\n",
              "      <td>1.359876</td>\n",
              "      <td>0.250705</td>\n",
              "      <td>0.273667</td>\n",
              "      <td>0.702699</td>\n",
              "      <td>0.154827</td>\n",
              "      <td>0.398550</td>\n",
              "      <td>2.456560</td>\n",
              "      <td>0.329126</td>\n",
              "      <td>0.408755</td>\n",
              "      <td>0.313415</td>\n",
              "      <td>0.691956</td>\n",
              "      <td>0.536860</td>\n",
              "      <td>0.360816</td>\n",
              "      <td>0.512824</td>\n",
              "      <td>0.351551</td>\n",
              "      <td>...</td>\n",
              "      <td>0.419095</td>\n",
              "      <td>0.393447</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.768113</td>\n",
              "      <td>0.185718</td>\n",
              "      <td>1.645807</td>\n",
              "      <td>0.296829</td>\n",
              "      <td>0.309345</td>\n",
              "      <td>1.206995</td>\n",
              "      <td>0.164650</td>\n",
              "      <td>0.160687</td>\n",
              "      <td>0.188221</td>\n",
              "      <td>0.104784</td>\n",
              "      <td>0.141983</td>\n",
              "      <td>0.167710</td>\n",
              "      <td>0.136838</td>\n",
              "      <td>0.116048</td>\n",
              "      <td>0.255528</td>\n",
              "      <td>0.140871</td>\n",
              "      <td>0.481227</td>\n",
              "      <td>0.251773</td>\n",
              "      <td>1.534835</td>\n",
              "      <td>2.009109</td>\n",
              "      <td>0.119524</td>\n",
              "      <td>0.997775</td>\n",
              "      <td>0.878668</td>\n",
              "      <td>0.205604</td>\n",
              "      <td>0.129954</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.104784</td>\n",
              "      <td>0.110694</td>\n",
              "      <td>0.434154</td>\n",
              "      <td>0.118481</td>\n",
              "      <td>0.140314</td>\n",
              "      <td>0.148380</td>\n",
              "      <td>1.839730</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         DYRK1A_N   ITSN1_N    BDNF_N  ...  Treatment  Behavior   class\n",
              "MouseID                                ...                             \n",
              "309_1    0.503644  0.747193  0.430175  ...  Memantine       C/S  c-CS-m\n",
              "309_2    0.514617  0.689064  0.411770  ...  Memantine       C/S  c-CS-m\n",
              "309_3    0.509183  0.730247  0.418309  ...  Memantine       C/S  c-CS-m\n",
              "309_4    0.442107  0.617076  0.358626  ...  Memantine       C/S  c-CS-m\n",
              "309_5    0.434940  0.617430  0.358802  ...  Memantine       C/S  c-CS-m\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iI7Jr_eFw_x"
      },
      "source": [
        "Replacing missing values by mean value of each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF90NF2yFdjH",
        "outputId": "814b1f94-c68c-40e3-ce03-28e80aae2bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "df1 = df.where(pd.notna(df), df.mean(), axis='columns')\n",
        "xnames = df1.columns\n",
        "df1.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DYRK1A_N</th>\n",
              "      <th>ITSN1_N</th>\n",
              "      <th>BDNF_N</th>\n",
              "      <th>NR1_N</th>\n",
              "      <th>NR2A_N</th>\n",
              "      <th>pAKT_N</th>\n",
              "      <th>pBRAF_N</th>\n",
              "      <th>pCAMKII_N</th>\n",
              "      <th>pCREB_N</th>\n",
              "      <th>pELK_N</th>\n",
              "      <th>pERK_N</th>\n",
              "      <th>pJNK_N</th>\n",
              "      <th>PKCA_N</th>\n",
              "      <th>pMEK_N</th>\n",
              "      <th>pNR1_N</th>\n",
              "      <th>pNR2A_N</th>\n",
              "      <th>pNR2B_N</th>\n",
              "      <th>pPKCAB_N</th>\n",
              "      <th>pRSK_N</th>\n",
              "      <th>AKT_N</th>\n",
              "      <th>BRAF_N</th>\n",
              "      <th>CAMKII_N</th>\n",
              "      <th>CREB_N</th>\n",
              "      <th>ELK_N</th>\n",
              "      <th>ERK_N</th>\n",
              "      <th>GSK3B_N</th>\n",
              "      <th>JNK_N</th>\n",
              "      <th>MEK_N</th>\n",
              "      <th>TRKA_N</th>\n",
              "      <th>RSK_N</th>\n",
              "      <th>APP_N</th>\n",
              "      <th>Bcatenin_N</th>\n",
              "      <th>SOD1_N</th>\n",
              "      <th>MTOR_N</th>\n",
              "      <th>P38_N</th>\n",
              "      <th>pMTOR_N</th>\n",
              "      <th>DSCR1_N</th>\n",
              "      <th>AMPKA_N</th>\n",
              "      <th>NR2B_N</th>\n",
              "      <th>pNUMB_N</th>\n",
              "      <th>...</th>\n",
              "      <th>TIAM1_N</th>\n",
              "      <th>pP70S6_N</th>\n",
              "      <th>NUMB_N</th>\n",
              "      <th>P70S6_N</th>\n",
              "      <th>pGSK3B_N</th>\n",
              "      <th>pPKCG_N</th>\n",
              "      <th>CDK5_N</th>\n",
              "      <th>S6_N</th>\n",
              "      <th>ADARB1_N</th>\n",
              "      <th>AcetylH3K9_N</th>\n",
              "      <th>RRP1_N</th>\n",
              "      <th>BAX_N</th>\n",
              "      <th>ARC_N</th>\n",
              "      <th>ERBB4_N</th>\n",
              "      <th>nNOS_N</th>\n",
              "      <th>Tau_N</th>\n",
              "      <th>GFAP_N</th>\n",
              "      <th>GluR3_N</th>\n",
              "      <th>GluR4_N</th>\n",
              "      <th>IL1B_N</th>\n",
              "      <th>P3525_N</th>\n",
              "      <th>pCASP9_N</th>\n",
              "      <th>PSD95_N</th>\n",
              "      <th>SNCA_N</th>\n",
              "      <th>Ubiquitin_N</th>\n",
              "      <th>pGSK3B_Tyr216_N</th>\n",
              "      <th>SHH_N</th>\n",
              "      <th>BAD_N</th>\n",
              "      <th>BCL2_N</th>\n",
              "      <th>pS6_N</th>\n",
              "      <th>pCFOS_N</th>\n",
              "      <th>SYP_N</th>\n",
              "      <th>H3AcK18_N</th>\n",
              "      <th>EGR1_N</th>\n",
              "      <th>H3MeK4_N</th>\n",
              "      <th>CaNA_N</th>\n",
              "      <th>Genotype</th>\n",
              "      <th>Treatment</th>\n",
              "      <th>Behavior</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MouseID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>309_1</th>\n",
              "      <td>0.503644</td>\n",
              "      <td>0.747193</td>\n",
              "      <td>0.430175</td>\n",
              "      <td>2.816329</td>\n",
              "      <td>5.990152</td>\n",
              "      <td>0.218830</td>\n",
              "      <td>0.177565</td>\n",
              "      <td>2.373744</td>\n",
              "      <td>0.232224</td>\n",
              "      <td>1.750936</td>\n",
              "      <td>0.687906</td>\n",
              "      <td>0.306382</td>\n",
              "      <td>0.402698</td>\n",
              "      <td>0.296927</td>\n",
              "      <td>1.022060</td>\n",
              "      <td>0.605673</td>\n",
              "      <td>1.877684</td>\n",
              "      <td>2.308745</td>\n",
              "      <td>0.441599</td>\n",
              "      <td>0.859366</td>\n",
              "      <td>0.416289</td>\n",
              "      <td>0.369608</td>\n",
              "      <td>0.178944</td>\n",
              "      <td>1.866358</td>\n",
              "      <td>3.685247</td>\n",
              "      <td>1.537227</td>\n",
              "      <td>0.264526</td>\n",
              "      <td>0.319677</td>\n",
              "      <td>0.813866</td>\n",
              "      <td>0.165846</td>\n",
              "      <td>0.453910</td>\n",
              "      <td>3.037621</td>\n",
              "      <td>0.369510</td>\n",
              "      <td>0.458539</td>\n",
              "      <td>0.335336</td>\n",
              "      <td>0.825192</td>\n",
              "      <td>0.576916</td>\n",
              "      <td>0.448099</td>\n",
              "      <td>0.586271</td>\n",
              "      <td>0.394721</td>\n",
              "      <td>...</td>\n",
              "      <td>0.482864</td>\n",
              "      <td>0.294170</td>\n",
              "      <td>0.182150</td>\n",
              "      <td>0.842725</td>\n",
              "      <td>0.192608</td>\n",
              "      <td>1.443091</td>\n",
              "      <td>0.294700</td>\n",
              "      <td>0.354605</td>\n",
              "      <td>1.339070</td>\n",
              "      <td>0.170119</td>\n",
              "      <td>0.159102</td>\n",
              "      <td>0.188852</td>\n",
              "      <td>0.106305</td>\n",
              "      <td>0.144989</td>\n",
              "      <td>0.176668</td>\n",
              "      <td>0.125190</td>\n",
              "      <td>0.115291</td>\n",
              "      <td>0.228043</td>\n",
              "      <td>0.142756</td>\n",
              "      <td>0.430957</td>\n",
              "      <td>0.247538</td>\n",
              "      <td>1.603310</td>\n",
              "      <td>2.014875</td>\n",
              "      <td>0.108234</td>\n",
              "      <td>1.044979</td>\n",
              "      <td>0.831557</td>\n",
              "      <td>0.188852</td>\n",
              "      <td>0.122652</td>\n",
              "      <td>0.134762</td>\n",
              "      <td>0.106305</td>\n",
              "      <td>0.108336</td>\n",
              "      <td>0.427099</td>\n",
              "      <td>0.114783</td>\n",
              "      <td>0.131790</td>\n",
              "      <td>0.128186</td>\n",
              "      <td>1.675652</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_2</th>\n",
              "      <td>0.514617</td>\n",
              "      <td>0.689064</td>\n",
              "      <td>0.411770</td>\n",
              "      <td>2.789514</td>\n",
              "      <td>5.685038</td>\n",
              "      <td>0.211636</td>\n",
              "      <td>0.172817</td>\n",
              "      <td>2.292150</td>\n",
              "      <td>0.226972</td>\n",
              "      <td>1.596377</td>\n",
              "      <td>0.695006</td>\n",
              "      <td>0.299051</td>\n",
              "      <td>0.385987</td>\n",
              "      <td>0.281319</td>\n",
              "      <td>0.956676</td>\n",
              "      <td>0.587559</td>\n",
              "      <td>1.725774</td>\n",
              "      <td>2.043037</td>\n",
              "      <td>0.445222</td>\n",
              "      <td>0.834659</td>\n",
              "      <td>0.400364</td>\n",
              "      <td>0.356178</td>\n",
              "      <td>0.173680</td>\n",
              "      <td>1.761047</td>\n",
              "      <td>3.485287</td>\n",
              "      <td>1.509249</td>\n",
              "      <td>0.255727</td>\n",
              "      <td>0.304419</td>\n",
              "      <td>0.780504</td>\n",
              "      <td>0.157194</td>\n",
              "      <td>0.430940</td>\n",
              "      <td>2.921882</td>\n",
              "      <td>0.342279</td>\n",
              "      <td>0.423560</td>\n",
              "      <td>0.324835</td>\n",
              "      <td>0.761718</td>\n",
              "      <td>0.545097</td>\n",
              "      <td>0.420876</td>\n",
              "      <td>0.545097</td>\n",
              "      <td>0.368255</td>\n",
              "      <td>...</td>\n",
              "      <td>0.454519</td>\n",
              "      <td>0.276431</td>\n",
              "      <td>0.182086</td>\n",
              "      <td>0.847615</td>\n",
              "      <td>0.194815</td>\n",
              "      <td>1.439460</td>\n",
              "      <td>0.294060</td>\n",
              "      <td>0.354548</td>\n",
              "      <td>1.306323</td>\n",
              "      <td>0.171427</td>\n",
              "      <td>0.158129</td>\n",
              "      <td>0.184570</td>\n",
              "      <td>0.106592</td>\n",
              "      <td>0.150471</td>\n",
              "      <td>0.178309</td>\n",
              "      <td>0.134275</td>\n",
              "      <td>0.118235</td>\n",
              "      <td>0.238073</td>\n",
              "      <td>0.142037</td>\n",
              "      <td>0.457156</td>\n",
              "      <td>0.257632</td>\n",
              "      <td>1.671738</td>\n",
              "      <td>2.004605</td>\n",
              "      <td>0.109749</td>\n",
              "      <td>1.009883</td>\n",
              "      <td>0.849270</td>\n",
              "      <td>0.200404</td>\n",
              "      <td>0.116682</td>\n",
              "      <td>0.134762</td>\n",
              "      <td>0.106592</td>\n",
              "      <td>0.104315</td>\n",
              "      <td>0.441581</td>\n",
              "      <td>0.111974</td>\n",
              "      <td>0.135103</td>\n",
              "      <td>0.131119</td>\n",
              "      <td>1.743610</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_3</th>\n",
              "      <td>0.509183</td>\n",
              "      <td>0.730247</td>\n",
              "      <td>0.418309</td>\n",
              "      <td>2.687201</td>\n",
              "      <td>5.622059</td>\n",
              "      <td>0.209011</td>\n",
              "      <td>0.175722</td>\n",
              "      <td>2.283337</td>\n",
              "      <td>0.230247</td>\n",
              "      <td>1.561316</td>\n",
              "      <td>0.677348</td>\n",
              "      <td>0.291276</td>\n",
              "      <td>0.381002</td>\n",
              "      <td>0.281710</td>\n",
              "      <td>1.003635</td>\n",
              "      <td>0.602449</td>\n",
              "      <td>1.731873</td>\n",
              "      <td>2.017984</td>\n",
              "      <td>0.467668</td>\n",
              "      <td>0.814329</td>\n",
              "      <td>0.399847</td>\n",
              "      <td>0.368089</td>\n",
              "      <td>0.173905</td>\n",
              "      <td>1.765544</td>\n",
              "      <td>3.571456</td>\n",
              "      <td>1.501244</td>\n",
              "      <td>0.259614</td>\n",
              "      <td>0.311747</td>\n",
              "      <td>0.785154</td>\n",
              "      <td>0.160895</td>\n",
              "      <td>0.423187</td>\n",
              "      <td>2.944136</td>\n",
              "      <td>0.343696</td>\n",
              "      <td>0.425005</td>\n",
              "      <td>0.324852</td>\n",
              "      <td>0.757031</td>\n",
              "      <td>0.543620</td>\n",
              "      <td>0.404630</td>\n",
              "      <td>0.552994</td>\n",
              "      <td>0.363880</td>\n",
              "      <td>...</td>\n",
              "      <td>0.447197</td>\n",
              "      <td>0.256648</td>\n",
              "      <td>0.184388</td>\n",
              "      <td>0.856166</td>\n",
              "      <td>0.200737</td>\n",
              "      <td>1.524364</td>\n",
              "      <td>0.301881</td>\n",
              "      <td>0.386087</td>\n",
              "      <td>1.279600</td>\n",
              "      <td>0.185456</td>\n",
              "      <td>0.148696</td>\n",
              "      <td>0.190532</td>\n",
              "      <td>0.108303</td>\n",
              "      <td>0.145330</td>\n",
              "      <td>0.176213</td>\n",
              "      <td>0.132560</td>\n",
              "      <td>0.117760</td>\n",
              "      <td>0.244817</td>\n",
              "      <td>0.142445</td>\n",
              "      <td>0.510472</td>\n",
              "      <td>0.255343</td>\n",
              "      <td>1.663550</td>\n",
              "      <td>2.016831</td>\n",
              "      <td>0.108196</td>\n",
              "      <td>0.996848</td>\n",
              "      <td>0.846709</td>\n",
              "      <td>0.193685</td>\n",
              "      <td>0.118508</td>\n",
              "      <td>0.134762</td>\n",
              "      <td>0.108303</td>\n",
              "      <td>0.106219</td>\n",
              "      <td>0.435777</td>\n",
              "      <td>0.111883</td>\n",
              "      <td>0.133362</td>\n",
              "      <td>0.127431</td>\n",
              "      <td>1.926427</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_4</th>\n",
              "      <td>0.442107</td>\n",
              "      <td>0.617076</td>\n",
              "      <td>0.358626</td>\n",
              "      <td>2.466947</td>\n",
              "      <td>4.979503</td>\n",
              "      <td>0.222886</td>\n",
              "      <td>0.176463</td>\n",
              "      <td>2.152301</td>\n",
              "      <td>0.207004</td>\n",
              "      <td>1.595086</td>\n",
              "      <td>0.583277</td>\n",
              "      <td>0.296729</td>\n",
              "      <td>0.377087</td>\n",
              "      <td>0.313832</td>\n",
              "      <td>0.875390</td>\n",
              "      <td>0.520293</td>\n",
              "      <td>1.566852</td>\n",
              "      <td>2.132754</td>\n",
              "      <td>0.477671</td>\n",
              "      <td>0.727705</td>\n",
              "      <td>0.385639</td>\n",
              "      <td>0.362970</td>\n",
              "      <td>0.179449</td>\n",
              "      <td>1.286277</td>\n",
              "      <td>2.970137</td>\n",
              "      <td>1.419710</td>\n",
              "      <td>0.259536</td>\n",
              "      <td>0.279218</td>\n",
              "      <td>0.734492</td>\n",
              "      <td>0.162210</td>\n",
              "      <td>0.410615</td>\n",
              "      <td>2.500204</td>\n",
              "      <td>0.344509</td>\n",
              "      <td>0.429211</td>\n",
              "      <td>0.330121</td>\n",
              "      <td>0.746980</td>\n",
              "      <td>0.546763</td>\n",
              "      <td>0.386860</td>\n",
              "      <td>0.547849</td>\n",
              "      <td>0.366771</td>\n",
              "      <td>...</td>\n",
              "      <td>0.442650</td>\n",
              "      <td>0.398534</td>\n",
              "      <td>0.161768</td>\n",
              "      <td>0.760234</td>\n",
              "      <td>0.184169</td>\n",
              "      <td>1.612382</td>\n",
              "      <td>0.296382</td>\n",
              "      <td>0.290680</td>\n",
              "      <td>1.198765</td>\n",
              "      <td>0.159799</td>\n",
              "      <td>0.166112</td>\n",
              "      <td>0.185323</td>\n",
              "      <td>0.103184</td>\n",
              "      <td>0.140656</td>\n",
              "      <td>0.163804</td>\n",
              "      <td>0.123210</td>\n",
              "      <td>0.117439</td>\n",
              "      <td>0.234947</td>\n",
              "      <td>0.145068</td>\n",
              "      <td>0.430996</td>\n",
              "      <td>0.251103</td>\n",
              "      <td>1.484624</td>\n",
              "      <td>1.957233</td>\n",
              "      <td>0.119883</td>\n",
              "      <td>0.990225</td>\n",
              "      <td>0.833277</td>\n",
              "      <td>0.192112</td>\n",
              "      <td>0.132781</td>\n",
              "      <td>0.134762</td>\n",
              "      <td>0.103184</td>\n",
              "      <td>0.111262</td>\n",
              "      <td>0.391691</td>\n",
              "      <td>0.130405</td>\n",
              "      <td>0.147444</td>\n",
              "      <td>0.146901</td>\n",
              "      <td>1.700563</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309_5</th>\n",
              "      <td>0.434940</td>\n",
              "      <td>0.617430</td>\n",
              "      <td>0.358802</td>\n",
              "      <td>2.365785</td>\n",
              "      <td>4.718679</td>\n",
              "      <td>0.213106</td>\n",
              "      <td>0.173627</td>\n",
              "      <td>2.134014</td>\n",
              "      <td>0.192158</td>\n",
              "      <td>1.504230</td>\n",
              "      <td>0.550960</td>\n",
              "      <td>0.286961</td>\n",
              "      <td>0.363502</td>\n",
              "      <td>0.277964</td>\n",
              "      <td>0.864912</td>\n",
              "      <td>0.507990</td>\n",
              "      <td>1.480059</td>\n",
              "      <td>2.013697</td>\n",
              "      <td>0.483416</td>\n",
              "      <td>0.687794</td>\n",
              "      <td>0.367531</td>\n",
              "      <td>0.355311</td>\n",
              "      <td>0.174836</td>\n",
              "      <td>1.324695</td>\n",
              "      <td>2.896334</td>\n",
              "      <td>1.359876</td>\n",
              "      <td>0.250705</td>\n",
              "      <td>0.273667</td>\n",
              "      <td>0.702699</td>\n",
              "      <td>0.154827</td>\n",
              "      <td>0.398550</td>\n",
              "      <td>2.456560</td>\n",
              "      <td>0.329126</td>\n",
              "      <td>0.408755</td>\n",
              "      <td>0.313415</td>\n",
              "      <td>0.691956</td>\n",
              "      <td>0.536860</td>\n",
              "      <td>0.360816</td>\n",
              "      <td>0.512824</td>\n",
              "      <td>0.351551</td>\n",
              "      <td>...</td>\n",
              "      <td>0.419095</td>\n",
              "      <td>0.393447</td>\n",
              "      <td>0.160200</td>\n",
              "      <td>0.768113</td>\n",
              "      <td>0.185718</td>\n",
              "      <td>1.645807</td>\n",
              "      <td>0.296829</td>\n",
              "      <td>0.309345</td>\n",
              "      <td>1.206995</td>\n",
              "      <td>0.164650</td>\n",
              "      <td>0.160687</td>\n",
              "      <td>0.188221</td>\n",
              "      <td>0.104784</td>\n",
              "      <td>0.141983</td>\n",
              "      <td>0.167710</td>\n",
              "      <td>0.136838</td>\n",
              "      <td>0.116048</td>\n",
              "      <td>0.255528</td>\n",
              "      <td>0.140871</td>\n",
              "      <td>0.481227</td>\n",
              "      <td>0.251773</td>\n",
              "      <td>1.534835</td>\n",
              "      <td>2.009109</td>\n",
              "      <td>0.119524</td>\n",
              "      <td>0.997775</td>\n",
              "      <td>0.878668</td>\n",
              "      <td>0.205604</td>\n",
              "      <td>0.129954</td>\n",
              "      <td>0.134762</td>\n",
              "      <td>0.104784</td>\n",
              "      <td>0.110694</td>\n",
              "      <td>0.434154</td>\n",
              "      <td>0.118481</td>\n",
              "      <td>0.140314</td>\n",
              "      <td>0.148380</td>\n",
              "      <td>1.839730</td>\n",
              "      <td>Control</td>\n",
              "      <td>Memantine</td>\n",
              "      <td>C/S</td>\n",
              "      <td>c-CS-m</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 81 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         DYRK1A_N   ITSN1_N    BDNF_N  ...  Treatment  Behavior   class\n",
              "MouseID                                ...                             \n",
              "309_1    0.503644  0.747193  0.430175  ...  Memantine       C/S  c-CS-m\n",
              "309_2    0.514617  0.689064  0.411770  ...  Memantine       C/S  c-CS-m\n",
              "309_3    0.509183  0.730247  0.418309  ...  Memantine       C/S  c-CS-m\n",
              "309_4    0.442107  0.617076  0.358626  ...  Memantine       C/S  c-CS-m\n",
              "309_5    0.434940  0.617430  0.358802  ...  Memantine       C/S  c-CS-m\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51UFZYLbF6d5"
      },
      "source": [
        "**Binary Classification for Down's Syndrome**\n",
        "\n",
        "Getting numeric vector y indicating binary values of column \"Genotype\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIhGcgsqGHN7"
      },
      "source": [
        "yraw, y = np.unique(df1['Genotype'].values, return_inverse=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxZ5jfN7Mz49"
      },
      "source": [
        "Getting data from dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy0GRgbWL7Tx",
        "outputId": "5451d28d-c41e-429b-81fc-c1f5a1c6de0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X = np.array(df1.iloc[:,:-4]) \n",
        "X.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1080, 77)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BozfgR6JOISe"
      },
      "source": [
        "Splitting training and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZi9WjA5OKln"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "Xtr, Xts, ytr, yts = train_test_split(X,y, test_size=0.30)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRZD_OdyOpdi"
      },
      "source": [
        "Scaling the data using standard scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY2KF2QSOmCu"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scal = StandardScaler()\n",
        "Xtr1 = scal.fit_transform(Xtr)\n",
        "Xts1 = scal.transform(Xts)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeLsaUY_O_2W"
      },
      "source": [
        "Fitting logistic regression model on scaled training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJjPbnKrO-mc",
        "outputId": "fc4b031c-48bf-47bd-b848-8ebf335ff754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "logreg = linear_model.LogisticRegression(C=1e5, solver='liblinear')\n",
        "logreg.fit(Xtr1, ytr)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFvveEqxPy7h"
      },
      "source": [
        "Measuring classifier accuracy on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep4AUhHbPpQL",
        "outputId": "a56bed6a-ff22-439a-c711-74ff04e30b29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "yhat = logreg.predict(Xts1)\n",
        "acc = np.mean(yhat == yts)\n",
        "print(\"Accuracy on test data = %f\" % acc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data = 0.956790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ibzl3s-mP4J5"
      },
      "source": [
        "Interpreting the weight vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAOybV8TSefI",
        "outputId": "33d7147a-930e-4df5-baac-c045438081d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "W = np.reshape(logreg.coef_, newshape=-1)\n",
        "plt.stem(W, use_line_collection=True)\n",
        "plt.xlabel(\"W\")\n",
        "plt.grid()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5Sh2Sa4-yvH"
      },
      "source": [
        "Finding names of the genes fir two components i where magnitude W[i] is largest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWr8jsCC85uF",
        "outputId": "e553c302-9f50-4845-c364-18413f5a6c85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "max = np.argsort(np.abs(W))\n",
        "for i in range(2):\n",
        "  j = max[i]\n",
        "  print('%10s %12f' % (xnames[j], W[j]) )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bcatenin_N    -0.064798\n",
            "   pNUMB_N     0.308392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tsa74zcYBA_-"
      },
      "source": [
        "**Cross Validation**\n",
        "\n",
        "Performing 10-fold cross validation to obtain slightly better result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZuvnc_l9BdU",
        "outputId": "a13588c4-4458-4c96-f936-8ddf708b2eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "nfold = 10\n",
        "kf = KFold(n_splits=nfold, shuffle=True)\n",
        "acc = np.zeros(nfold)\n",
        "prec = np.zeros(nfold)\n",
        "rec = np.zeros(nfold)\n",
        "f1 = np.zeros(nfold)\n",
        "\n",
        "for i, I in enumerate(kf.split(X)):\n",
        "    \n",
        "    # Get training and test data\n",
        "    train, test = I\n",
        "    Xtr = X[train,:]\n",
        "    ytr = y[train]\n",
        "    Xts = X[test,:]\n",
        "    yts = y[test]\n",
        "    \n",
        "    # Scale the data\n",
        "    scal = StandardScaler()\n",
        "    Xtr1 = scal.fit_transform(Xtr)\n",
        "    Xts1 = scal.transform(Xts)    \n",
        "    \n",
        "    # Fit a model    \n",
        "    logreg.fit(Xtr1, ytr)\n",
        "    \n",
        "    # Predict on test samples and measure accuracy\n",
        "    yhat = logreg.predict(Xts1)\n",
        "    acc[i] = np.mean(yhat == yts)\n",
        "    \n",
        "    # Measure other performance metrics\n",
        "    prec[i],rec[i],f1[i],_  = precision_recall_fscore_support(yts,yhat,average='binary') \n",
        "    \n",
        "\n",
        "# Take average values of the metrics\n",
        "precm = np.mean(prec)\n",
        "recm = np.mean(rec)\n",
        "f1m = np.mean(f1)\n",
        "accm= np.mean(acc)\n",
        "\n",
        "# Compute the standard errors\n",
        "prec_se = np.std(prec)/np.sqrt(nfold-1)\n",
        "rec_se = np.std(rec)/np.sqrt(nfold-1)\n",
        "f1_se = np.std(f1)/np.sqrt(nfold-1)\n",
        "acc_se = np.std(acc)/np.sqrt(nfold-1)\n",
        "\n",
        "print('Precision = {0:.4f}, SE={1:.4f}'.format(precm,prec_se))\n",
        "print('Recall =    {0:.4f}, SE={1:.4f}'.format(recm, rec_se))\n",
        "print('f1 =        {0:.4f}, SE={1:.4f}'.format(f1m, f1_se))\n",
        "print('Accuracy =  {0:.4f}, SE={1:.4f}'.format(accm, acc_se))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision = 0.9530, SE=0.0094\n",
            "Recall =    0.9621, SE=0.0092\n",
            "f1 =        0.9571, SE=0.0060\n",
            "Accuracy =  0.9593, SE=0.0059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgMogjfkDGAm"
      },
      "source": [
        "**Multi Class Classification**\n",
        "\n",
        "Using df1['class'] which has 8 possible classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kyt08cIUDKhW",
        "outputId": "a8cc3913-75be-488e-b640-94a08eab06ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "yraw, y1 = np.unique(df1['class'].values, return_inverse=True)\n",
        "Xtr, Xts, ytr, yts = train_test_split(X, y1, test_size=0.30)\n",
        "\n",
        "scal = StandardScaler()\n",
        "Xtr1 = scal.fit_transform(Xtr)\n",
        "Xts1 = scal.transform(Xts)\n",
        "\n",
        "logreg1 = linear_model.LogisticRegression(C=1e5, solver='liblinear')\n",
        "logreg1.fit(Xtr1, ytr)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DabhDj-_DVWb",
        "outputId": "e047178e-f794-4d87-bbae-4f35366bd4db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "nfold = 10\n",
        "kf = KFold(n_splits=nfold, shuffle=True)\n",
        "acc = np.zeros(nfold)\n",
        "prec = np.zeros(nfold)\n",
        "rec = np.zeros(nfold)\n",
        "f1 = np.zeros(nfold)\n",
        "C = np.zeros((8,8))\n",
        "\n",
        "for i, I in enumerate(kf.split(X)):\n",
        "    \n",
        "    # Get training and test data\n",
        "    train, test = I\n",
        "    Xtr = X[train,:]\n",
        "    ytr = y1[train]\n",
        "    Xts = X[test,:]\n",
        "    yts = y1[test]\n",
        "    \n",
        "    # Scale the data\n",
        "    scal = StandardScaler()\n",
        "    Xtr1 = scal.fit_transform(Xtr)\n",
        "    Xts1 = scal.transform(Xts)    \n",
        "    \n",
        "    # Fit a model    \n",
        "    logreg.fit(Xtr1, ytr)\n",
        "    \n",
        "    # Predict on test samples and measure accuracy\n",
        "    yhat = logreg.predict(Xts1)\n",
        "    acc[i] = np.mean(yhat == yts)\n",
        "    C += confusion_matrix(yts,yhat,labels=np.unique(y1))\n",
        "\n",
        "    # Measure other performance metrics\n",
        "    prec[i],rec[i],f1[i],_  = precision_recall_fscore_support(yts,yhat, average='macro') \n",
        "    \n",
        "\n",
        "# Take average values of the metrics\n",
        "precm = np.mean(prec)\n",
        "recm = np.mean(rec)\n",
        "f1m = np.mean(f1)\n",
        "accm= np.mean(acc)\n",
        "\n",
        "# Compute the standard errors\n",
        "prec_se = np.std(prec)/np.sqrt(nfold-1)\n",
        "rec_se = np.std(rec)/np.sqrt(nfold-1)\n",
        "f1_se = np.std(f1)/np.sqrt(nfold-1)\n",
        "acc_se = np.std(acc)/np.sqrt(nfold-1)\n",
        "\n",
        "print('Precision = {0:.4f}, SE={1:.4f}'.format(precm,prec_se))\n",
        "print('Recall =    {0:.4f}, SE={1:.4f}'.format(recm, rec_se))\n",
        "print('f1 =        {0:.4f}, SE={1:.4f}'.format(f1m, f1_se))\n",
        "print('Accuracy =  {0:.4f}, SE={1:.4f}'.format(accm, acc_se))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision = 0.9863, SE=0.0029\n",
            "Recall =    0.9855, SE=0.0031\n",
            "f1 =        0.9853, SE=0.0031\n",
            "Accuracy =  0.9861, SE=0.0028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB1fphdnvPOm",
        "outputId": "c9b9ca02-9d7e-46ad-cc7c-4a1fa7f3bcba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "for i in range(8):\n",
        "  C[i]=C[i]/np.sum(C[i])\n",
        "print(np.array_str(C, precision=4, suppress_small=True))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9667 0.0133 0.0067 0.     0.0067 0.0067 0.     0.    ]\n",
            " [0.0148 0.9778 0.     0.     0.0074 0.     0.     0.    ]\n",
            " [0.     0.0133 0.98   0.     0.     0.     0.     0.0067]\n",
            " [0.0074 0.     0.     0.9852 0.0074 0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
            " [0.     0.0074 0.     0.0074 0.     0.     0.9852 0.    ]\n",
            " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ko5nYB4USX07"
      },
      "source": [
        "Re-running logistic regression on the entire training data to get weight coefficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bWXGDCHU9Z_",
        "outputId": "4ca477d7-4cb6-4cb2-a7e5-54f50eab8355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "scal = StandardScaler()\n",
        "Xtr1 = scal.fit_transform(X)\n",
        "logreg = linear_model.LogisticRegression(C=1e5, solver='liblinear')\n",
        "logreg.fit(Xtr1, y1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwZ6rbODW7yz",
        "outputId": "f24e3d1b-73f8-4aed-ca4b-29f4f5becfc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "W = logreg.coef_[0,:]\n",
        "plt.stem(W, use_line_collection=True)\n",
        "plt.xlabel(\"W\")\n",
        "plt.grid()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reM3H56ECOcI"
      },
      "source": [
        "Bonus Section: L1 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIsF2AppCRID"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "nfold = 10\n",
        "kf =KFold(nfold, shuffle=True)\n",
        "\n",
        "alphas = np.logspace(-0.005,10,20)\n",
        "nalpha = len(alphas)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPukBFvGFBep",
        "outputId": "0778e755-5e72-48b3-822d-25cf39009db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "nfold = 10\n",
        "kf = KFold(n_splits=nfold, shuffle=True)\n",
        "nalpha = len(alphas)\n",
        "acc = np.zeros((nfold, nalpha))\n",
        "prec = np.zeros((nfold,nalpha))\n",
        "rec = np.zeros((nfold, nalpha))\n",
        "f1 = np.zeros((nfold, nalpha))\n",
        "\n",
        "for ifold, ind in enumerate(kf.split(X)):\n",
        "        \n",
        "    # Get the training data in the split\n",
        "    Itr,Its = ind\n",
        "    Xtr = X[Itr,:]\n",
        "    ytr = y1[Itr]\n",
        "    Xts = X[Its,:]\n",
        "    yts = y1[Its]\n",
        "    \n",
        "    # Fit and transform the data\n",
        "    xscal = StandardScaler()\n",
        "    Xtr1 = xscal.fit_transform(Xtr)\n",
        "    Xts1 = xscal.transform(Xts)\n",
        "\n",
        "    for i, alpha in enumerate(alphas):\n",
        "\n",
        "        # Fit on the training data\n",
        "        reg = linear_model.LogisticRegression(penalty='l1', C=alpha, solver='liblinear')\n",
        "        reg.fit(Xtr1, ytr)\n",
        "\n",
        "        # Score on the test data\n",
        "        yhat1 = reg.predict(Xts1)\n",
        "        \n",
        "        acc[ifold][i] = np.mean(yhat == yts)\n",
        "        prec[ifold][i],rec[ifold][i],f1[ifold][i],_  = precision_recall_fscore_support(yts,yhat, average='macro')\n",
        "    \n",
        "    print('Fold = %d' % ifold)\n",
        "    precm = np.mean(prec[ifold])\n",
        "    recm = np.mean(rec[ifold])\n",
        "    f1m = np.mean(f1[ifold])\n",
        "    accm= np.mean(acc[ifold])\n",
        "\n",
        "    prec_se = np.std(prec)/np.sqrt(nfold-1)\n",
        "    rec_se = np.std(rec)/np.sqrt(nfold-1)\n",
        "    f1_se = np.std(f1)/np.sqrt(nfold-1)\n",
        "    acc_se = np.std(acc)/np.sqrt(nfold-1)\n",
        "\n",
        "    print('Precision = {0:.4f}, SE={1:.4f}'.format(precm,prec_se))  \n",
        "    print('Recall =    {0:.4f}, SE={1:.4f}'.format(recm, rec_se))\n",
        "    print('f1 =        {0:.4f}, SE={1:.4f}'.format(f1m, f1_se))\n",
        "    print('Accuracy =  {0:.4f}, SE={1:.4f}'.format(accm, acc_se))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold = 0\n",
            "Precision = 0.6766, SE=0.0677\n",
            "Recall =    0.6449, SE=0.0645\n",
            "f1 =        0.6293, SE=0.0629\n",
            "Accuracy =  0.6296, SE=0.0630\n",
            "Fold = 1\n",
            "Precision = 0.6561, SE=0.0889\n",
            "Recall =    0.6360, SE=0.0854\n",
            "f1 =        0.6160, SE=0.0830\n",
            "Accuracy =  0.6296, SE=0.0840\n",
            "Fold = 2\n",
            "Precision = 0.5895, SE=0.0981\n",
            "Recall =    0.5886, SE=0.0953\n",
            "f1 =        0.5674, SE=0.0924\n",
            "Accuracy =  0.6204, SE=0.0957\n",
            "Fold = 3\n",
            "Precision = 0.6808, SE=0.1065\n",
            "Recall =    0.6643, SE=0.1036\n",
            "f1 =        0.6382, SE=0.1002\n",
            "Accuracy =  0.6296, SE=0.1024\n",
            "Fold = 4\n",
            "Precision = 0.4925, SE=0.1045\n",
            "Recall =    0.5017, SE=0.1021\n",
            "f1 =        0.4760, SE=0.0986\n",
            "Accuracy =  0.4815, SE=0.1006\n",
            "Fold = 5\n",
            "Precision = 0.8107, SE=0.1092\n",
            "Recall =    0.8338, SE=0.1084\n",
            "f1 =        0.8031, SE=0.1046\n",
            "Accuracy =  0.8148, SE=0.1065\n",
            "Fold = 6\n",
            "Precision = 0.6671, SE=0.1029\n",
            "Recall =    0.6601, SE=0.1022\n",
            "f1 =        0.6188, SE=0.0982\n",
            "Accuracy =  0.6296, SE=0.1000\n",
            "Fold = 7\n",
            "Precision = 0.8093, SE=0.0944\n",
            "Recall =    0.7789, SE=0.0931\n",
            "f1 =        0.7719, SE=0.0902\n",
            "Accuracy =  0.7963, SE=0.0921\n",
            "Fold = 8\n",
            "Precision = 0.6895, SE=0.0736\n",
            "Recall =    0.6729, SE=0.0725\n",
            "f1 =        0.6487, SE=0.0705\n",
            "Accuracy =  0.6574, SE=0.0719\n",
            "Fold = 9\n",
            "Precision = 0.7394, SE=0.0301\n",
            "Recall =    0.7192, SE=0.0294\n",
            "f1 =        0.7082, SE=0.0301\n",
            "Accuracy =  0.7130, SE=0.0303\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}